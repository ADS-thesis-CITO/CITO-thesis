# Automatic School Handwriting Detection and Classification based on YOLO and Vision Transformers models
The last decade has marked a rapid and significant growth of deep learning networks. The biggest challenge lies in the identification and handling of object recognition. The aim of this research is to investigate whether it is possible to identify handwritten objects and classify them in a machine readable language. There are two models used in this thesis. You Only Look Once is built in Python and trained on a labeled dataset of 120 images from various handwritten numbers and multiple-choice circled answers, to determine the objects that are written by a student. Training results show that the mAP value is close to one, a maximum validation accuracy of 99% is achieved. To decrease overfitting and improve a more reliability validity, a larger validation dataset is needed. The second model is a Vision Transformers model and is trained separably on the MNIST dataset and custom labeled dataset. The highest testing results was provided by the MNIST dataset, which showed an accuracy of 99.5% on the testing set and an accuracy of 96.0% on the data that is provided by a third party company called Cito. 
